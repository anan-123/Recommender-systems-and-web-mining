# -*- coding: utf-8 -*-
"""258 hw2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/143gSftZ5utLOBzdiIfrYgIs-uBIFiNEu
"""

import numpy as np
import urllib
import scipy.optimize
import random
from sklearn import linear_model
import gzip
from collections import defaultdict
import warnings
warnings.filterwarnings("ignore")
def assertFloat(x):
    assert type(float(x)) == float

def assertFloatList(items, N):
    assert len(items) == N
    assert [type(float(x)) for x in items] == [float]*N
f = open("5year.arff", 'r')
# Read and parse the data
while not '@data' in f.readline():
    pass

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, balanced_accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
dataset = []
for l in f:
    if '?' in l: # Missing entry
        continue
    l = l.split(',')
    values = [1] + [float(x) for x in l]
    values[-1] = values[-1] > 0 # Convert to bool
    dataset.append(values)
X = [d[:-1] for d in dataset]
y = [d[-1] for d in dataset]
answers = {} # Your answers

### Question 1
mod = linear_model.LogisticRegression(C=1)
mod.fit(X,y)
y_pred = mod.predict(X)
acc = accuracy_score(y, y_pred)
cm = confusion_matrix(y, y_pred)
error_rates = (cm.sum(axis=1) - np.diag(cm)) / cm.sum(axis=1)
ber = np.nanmean(error_rates)
answers['Q1'] = [acc, ber]
print(answers['Q1'])
assertFloatList(answers['Q1'], 2)

### Question 2
mod = linear_model.LogisticRegression(C=1, class_weight='balanced')
mod.fit(X,y)

y_pred = mod.predict(X)
cm = confusion_matrix(y, y_pred)
error_rates = (cm.sum(axis=1) - np.diag(cm)) / cm.sum(axis=1)
ber = np.nanmean(error_rates)
acc = accuracy_score(y, y_pred)
answers['Q2'] = [acc, ber]
print(answers['Q2'])
assertFloatList(answers['Q2'], 2)

### Question 3
random.seed(3)
random.shuffle(dataset)
X = [d[:-1] for d in dataset]
y = [d[-1] for d in dataset]
X_train, X_valid, X_test = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]
y_train, y_valid, y_test = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]

import numpy as np
model = LogisticRegression(class_weight='balanced', max_iter=1000)
model.fit(X_train, y_train)

def calculate_ber(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    error_rates = (cm.sum(axis=1) - np.diag(cm)) / cm.sum(axis=1)
    return np.nanmean(error_rates)


y_train_pred = model.predict(X_train)
y_val_pred = model.predict(X_valid)
y_test_pred = model.predict(X_test)


train_ber = calculate_ber(y_train, y_train_pred)
val_ber = calculate_ber(y_valid, y_val_pred)
test_ber = calculate_ber(y_test, y_test_pred)


answers['Q3'] = [train_ber,val_ber,test_ber]
print(answers['Q3'])
assertFloatList(answers['Q3'], 3)

### Question 4
C_values = [10**i for i in range(-4, 5)]
ber_list = []


for C in C_values:
    mod = linear_model.LogisticRegression(C=C, class_weight='balanced')
    mod.fit(X, y)

    y_pred = mod.predict(X)
    ber = calculate_ber(y, y_pred)
    ber_list.append(ber)

ber_list



answers['Q4'] = ber_list
print(ber_list)
assertFloatList(answers['Q4'], 9)

### Question 5
best_index = np.argmin(ber_list)
best_c = C_values[best_index]
best_ber = ber_list[best_index]

answers['Q5'] = [best_c, best_ber]
print(answers['Q5'])
assertFloatList(answers['Q5'], 2)

### Question 6
f = gzip.open("young_adult_10000.json.gz")
dataset = []
for l in f:
    dataset.append(eval(l))
dataTrain = dataset[:9000]
dataTest = dataset[9000:]

# Some data structures you might want

usersPerItem = defaultdict(set) # Maps an item to the users who rated it
itemsPerUser = defaultdict(set) # Maps a user to the items that they rated
reviewsPerUser = defaultdict(list)
reviewsPerItem = defaultdict(list)
ratingDict = {} # To retrieve a rating for a specific user/item pair

for d in dataTrain:
    usersPerItem[d['book_id']].add(d['user_id'])
    itemsPerUser[d['user_id']].add(d['book_id'])
    reviewsPerUser[d['user_id']].append(d)
    reviewsPerItem[ d['book_id']].append(d)
    ratingDict[(d['user_id'],  d['book_id'])] = d['rating']

def Jaccard(s1, s2):
     return len(s1.intersection(s2)) / len(s1.union(s2)) if s1.union(s2) else 0

# def mostSimilar(i, N):
#     target_users = usersPerItem[i]
#     similarities = [
#         (Jaccard(target_users, usersPerItem[other_item]), other_item)
#         for other_item in usersPerItem if other_item != i
#     ]
#     return sorted(similarities, reverse=True)[:N]
def mostSimilar(i, N):
    similarities = []
    users = usersPerItem[i]
    candidateItems = set()
    for u in users:
        candidateItems = candidateItems.union(itemsPerUser[u])
    for i2 in candidateItems:
        if i2 == i: continue
        sim = Jaccard(users, usersPerItem[i2])
        similarities.append((sim,i2))
    similarities.sort(reverse=True)
    return similarities[:N]

answers['Q6'] = mostSimilar('2767052', 10)
print(answers['Q6'])
assert len(answers['Q6']) == 10
assertFloatList([x[0] for x in answers['Q6']], 10)

item_avg_ratings = {item_id: np.mean([r['rating'] for r in reviews]) for item_id, reviews in reviewsPerItem.items()}
ratingDict = {(r['user_id'], r['book_id']): r['rating'] for r in dataTrain}
usersPerItem = defaultdict(set)
itemsPerUser = defaultdict(set)
for r in dataTrain:
    itemsPerUser[r['user_id']].add(r['book_id'])
    usersPerItem[r['book_id']].add(r['user_id'])

def predict_rating(user_id, item_id):
    if item_id not in item_avg_ratings:
        return np.mean(list(item_avg_ratings.values()))
    avg_rating_i = item_avg_ratings[item_id]
    rated_items = itemsPerUser[user_id]
    sum_weighted_ratings = 0
    sum_similarities = 0
    for j in rated_items:
        if j != item_id:
            sum_weighted_ratings += (ratingDict.get((user_id, j), item_avg_ratings.get(j, 0))  -item_avg_ratings.get(j, 0)) *Jaccard(usersPerItem[item_id], usersPerItem[j])
            sum_similarities += Jaccard(usersPerItem[item_id], usersPerItem[j])
    if sum_similarities == 0:
        return avg_rating_i
    else:
        return avg_rating_i + (sum_weighted_ratings / sum_similarities)

def calculate_mse():
    total_error = 0
    count = 0
    for review in dataTest:
        count += 1
        total_error += (review['rating'] - predict_rating(review['user_id'],review['book_id'])) ** 2
    mse = total_error / count if count > 0 else 0
    return mse

mse7 = calculate_mse()

answers['Q7'] = mse7
assertFloat(answers['Q7'])

print(answers['Q7'])

itemsPerUser = defaultdict(set)
usersPerItem = defaultdict(set)
ratingDict = {}
user_avg_ratings = {}

for r in dataTrain:
    user_id, item_id, rating = r['user_id'], r['book_id'], r['rating']
    itemsPerUser[user_id].add(item_id)
    usersPerItem[item_id].add(user_id)
    ratingDict[(user_id, item_id)] = rating

for user_id, items in itemsPerUser.items():
    ratings = [ratingDict[(user_id, item_id)] for item_id in items]
    user_avg_ratings[user_id] = np.mean(ratings) if ratings else 0

def user_jaccard(u1, u2):
    return Jaccard(itemsPerUser[u1],itemsPerUser[u2])

def predict_rating_user_based(user_id, item_id):
    if user_id not in user_avg_ratings:
        return np.mean(list(user_avg_ratings.values()))
    avg_rating_u = user_avg_ratings[user_id]
    users_rated_i = usersPerItem[item_id]
    sum_weighted_ratings = 0
    sum_weights = 0

    for v in users_rated_i:
        if v != user_id:
            sum_weighted_ratings += (ratingDict.get((v, item_id), user_avg_ratings.get(v, 0)) - user_avg_ratings.get(v, 0)) * user_jaccard(user_id, v)
            sum_weights += user_jaccard(user_id, v)

    if sum_weights == 0:
        return avg_rating_u

    else:
        return avg_rating_u + (sum_weighted_ratings / sum_weights)

def calculate_mse_user_based():
    total_error = 0
    count = 0

    for review in dataTest:
        user_id = review['user_id']
        item_id = review['book_id']
        actual_rating = review['rating']

        predicted_rating = predict_rating_user_based(user_id, item_id)
        total_error += (actual_rating - predicted_rating) ** 2
        count += 1

    mse = total_error / count if count > 0 else 0
    return mse


mse8 = calculate_mse_user_based()

answers['Q8'] = mse8
assertFloat(answers['Q8'])
print(answers['Q8'])

f = open("answers_hw2.txt", 'w')
f.write(str(answers) + '\n')
f.close()

